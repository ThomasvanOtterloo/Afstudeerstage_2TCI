{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-03T15:16:27.037171800Z",
     "start_time": "2025-05-03T15:16:25.596972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu126\n",
      "Built with CUDA: 12.6\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-03T15:16:27.081992200Z",
     "start_time": "2025-05-03T15:16:27.039684200Z"
    }
   },
   "id": "32302be90eacaaa6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\Desktop\\school\\AfstudeerStage\\Afstudeerstage_2TCI\\AItransformer\\Transformer\\BaseTransformerModel.py:3: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastLanguageModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\anaconda3\\envs\\ETL\\lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4080. Num GPUs = 1. Max memory: 15.992 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "TransformerDecorator.__init__\n",
      "[{'ReferenceNumber': 'WSSA0039', 'Price': 50000, 'Condition': 'New', 'YearOfManufacture': '2025', 'FullSet': True, 'brand': 'Cartier'}]\n"
     ]
    }
   ],
   "source": [
    "from Transformer.BrandIdentifierDecorator import BrandIdentifierDecorator\n",
    "from Transformer.BaseTransformerModel import BaseTransformerModel\n",
    "import json\n",
    "# 1) your ‚Äúcore‚Äù model\n",
    "core = BaseTransformerModel() # isnt this supposed to be the TransformerDecorators?\n",
    "\n",
    "# 2) wrap it\n",
    "brand_decorated = BrandIdentifierDecorator(\n",
    "    core\n",
    ")\n",
    "# 3) use it\n",
    "json_dummy_ad = {\n",
    "    \"reference\": \"WSSA0039\",\n",
    "    \"price\": 50000,\n",
    "    \"condition\": \"New\",\n",
    "    \"year\": 2025,\n",
    "    \"fullset\": True\n",
    "}\n",
    "\n",
    "result = brand_decorated.transformData(json.dumps(json_dummy_ad))\n",
    "print(result)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-21T11:47:39.876809100Z",
     "start_time": "2025-05-21T11:47:24.629810400Z"
    }
   },
   "id": "99e112d7de2da313"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'Transformer.BrandIdentifierDecorator.BrandIdentifierDecorator'>, <class 'Transformer.TransformerDecorator.TransformerDecorator'>, <class 'Transformer.ITransformer.ITransformer'>, <class 'abc.ABC'>, <class 'object'>)\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getmro(BrandIdentifierDecorator))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-21T09:22:04.214126400Z",
     "start_time": "2025-05-21T09:22:04.199568300Z"
    }
   },
   "id": "dfcc3cf016064d97"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server',\n",
      " 'ODBC Driver 17 for SQL Server',\n",
      " 'Microsoft Access Driver (*.mdb, *.accdb)',\n",
      " 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)',\n",
      " 'Microsoft Access Text Driver (*.txt, *.csv)',\n",
      " 'Microsoft Access dBASE Driver (*.dbf, *.ndx, *.mdx)',\n",
      " 'ODBC Driver 18 for SQL Server']\n"
     ]
    }
   ],
   "source": [
    "import pyodbc, pprint\n",
    "pprint.pprint(pyodbc.drivers())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T14:08:24.707296700Z",
     "start_time": "2025-04-23T14:08:24.691290800Z"
    }
   },
   "id": "773febcec2ad0653"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unsloth', 'zephyr', 'chatml', 'mistral', 'llama', 'vicuna', 'vicuna_old', 'vicuna old', 'alpaca', 'gemma', 'gemma_chatml', 'gemma2', 'gemma2_chatml', 'llama-3', 'llama3', 'phi-3', 'phi-35', 'phi-3.5', 'llama-3.1', 'llama-31', 'llama-3.2', 'llama-3.3', 'llama-32', 'llama-33', 'qwen-2.5', 'qwen-25', 'qwen25', 'qwen2.5', 'phi-4', 'gemma-3', 'gemma3']\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import CHAT_TEMPLATES\n",
    "print(list(CHAT_TEMPLATES.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-30T06:25:14.103069600Z",
     "start_time": "2025-04-30T06:25:14.092429Z"
    }
   },
   "id": "946e2b5a143f9664"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ post_processing: Valid JSON detected. \n",
      " [{'Brand': 'Patek', 'Model': '7150', 'ReferenceNumber': '7150/250R', 'YearOfManufacture': '02/2025', 'Condition': 'New', 'FullSet': True, 'Price': 52000, 'Currency': 'USDT'}, {'Brand': 'RM011', 'Model': 'WG Felipe Massa', 'YearOfManufacture': '2013', 'Condition': 'like new', 'Price': 150000, 'Currency': 'USDT'}, {'Brand': 'Vacheron Constantin', 'Model': 'Tourbillon', 'ReferenceNumber': '6000V/110R-B934', 'YearOfManufacture': '2022', 'Condition': 'Brand new', 'Price': 175000, 'Currency': 'USDT'}, {'Brand': 'RM39', 'Model': '01aviation', 'YearOfManufacture': '2015', 'Condition': 'like new', 'Price': 92000, 'Currency': 'USDT'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# from openai import OpenAI\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "# python3 -m vllm.entrypoints.openai.api_server --model Qwen/Qwen3-8B-FP8 --max-model-len 10000\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "with open(\"Transformer/system_prompt.txt\", encoding=\"utf-8\") as f:\n",
    "   system_prompt = f.read()\n",
    "   \n",
    "   \n",
    "prompt1 = \"\"\"\n",
    "üì¢Good price in the market\n",
    "Patek 7150/250R\n",
    "New - 02/2025 - Fullset\n",
    "52000 USDT\n",
    "\n",
    "RM011 WG Felipe Massa \n",
    "2013>> like new \n",
    "150.000 USDT\n",
    "\n",
    "Vacheron Constantin \n",
    "Tourbillon 2022\n",
    "Brand new \n",
    "6000V/110R-B934\n",
    "175.000 USDT\n",
    "\n",
    "RM39 01aviation\n",
    "2015> like new¬†\n",
    "92000¬†USDT\n",
    "\"\"\"\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-8B-FP8\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt1},\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    max_tokens=8192,\n",
    "    presence_penalty=1.5,\n",
    "    extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}},\n",
    ")\n",
    "parsed_output = json.loads(chat_response.choices[0].message.content)\n",
    "print(\"‚úÖ post_processing: Valid JSON detected. \\n\", parsed_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-30T06:25:48.272817100Z",
     "start_time": "2025-04-30T06:25:37.037076200Z"
    }
   },
   "id": "cdf1c7ac2575af80"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\anaconda3\\envs\\ETL\\lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4080. Num GPUs = 1. Max memory: 15.992 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "893115c4edb7486ab09dd894abe8ebf3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content: The reference number **228235A** is associated with the **Omega Speedmaster** watch. Specifically, this reference was used for a **Speedmaster Moonwatch** model, which is one of Omega's most iconic and historically significant models.\n",
      "\n",
      "### Key Details:\n",
      "- **Brand:** Omega\n",
      "- **Model:** Speedmaster\n",
      "- **Reference:** 228235A\n",
      "- **Type:** Moonwatch (a variant of the Speedmaster)\n",
      "- **Year Range:** This reference was used in the **1970s**, specifically between **1973 and 1979**.\n",
      "- **Features:**\n",
      "  - It was a **chronograph** with a **tachymeter scale** on the bezel.\n",
      "  - It featured a **stainless steel case**, **sapphire crystal**, and a **black dial**.\n",
      "  - The **reference 228235A** is known for its **black dial with white markers** and a **black leather strap**.\n",
      "  - It was a **prestigious model** and often associated with **space exploration**, as the Speedmaster was the first watch worn on the moon during the Apollo missions.\n",
      "\n",
      "### Notable Use:\n",
      "- The **Speedmaster** was the official watch of NASA for the Apollo missions, and the **228235A** was one of the models used during that time.\n",
      "\n",
      "### Value:\n",
      "- This reference is **highly collectible**, especially if it has a **moonwatch certificate** or is in **good condition**.\n",
      "- The **rarity** and **historical significance** make it a **desirable watch** among collectors.\n",
      "\n",
      "If you have a specific watch with this reference, it would be helpful to know more details (e.g., condition, materials, any engravings) to give a more precise assessment.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "            max_seq_length=4092,\n",
    "            dtype=None,\n",
    "        )\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "#example\n",
    "prompt = \"Do you know what Watch brand this reference number is from? 228235A \"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "    # add system prompt.\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"content:\", content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-03T17:50:43.955897Z",
     "start_time": "2025-05-03T17:50:15.152088400Z"
    }
   },
   "id": "6d4e268c3caad0c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
