{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-29T18:47:43.657707200Z",
     "start_time": "2025-04-29T18:47:43.653963700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "Built with CUDA: 12.4\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T18:47:49.128001500Z",
     "start_time": "2025-04-29T18:47:49.116864Z"
    }
   },
   "id": "32302be90eacaaa6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication took 0.0694 seconds on the GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "a = torch.randn(10000, 10000, device=\"cuda\")\n",
    "b = torch.randn(10000, 10000, device=\"cuda\")\n",
    "\n",
    "start = time.time()\n",
    "c = torch.matmul(a, b)\n",
    "torch.cuda.synchronize()  # Ensure timing is accurate\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Matrix multiplication took {end - start:.4f} seconds on the GPU\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-29T18:47:39.271463900Z",
     "start_time": "2025-04-29T18:47:39.189965Z"
    }
   },
   "id": "48150e6039a859da"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drivers: ['SQL Server', 'ODBC Driver 17 for SQL Server', 'Microsoft Access Driver (*.mdb, *.accdb)', 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)', 'Microsoft Access Text Driver (*.txt, *.csv)', 'Microsoft Access dBASE Driver (*.dbf, *.ndx, *.mdx)']\n"
     ]
    },
    {
     "ename": "InterfaceError",
     "evalue": "('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInterfaceError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDrivers:\u001B[39m\u001B[38;5;124m\"\u001B[39m, pyodbc\u001B[38;5;241m.\u001B[39mdrivers())\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Try connecting DSN-less\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m conn \u001B[38;5;241m=\u001B[39m \u001B[43mpyodbc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDriver=\u001B[39;49m\u001B[38;5;124;43m{\u001B[39;49m\u001B[38;5;124;43mODBC Driver 18 for SQL Server};Server=localhost;Trusted_Connection=yes;\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "\u001B[1;31mInterfaceError\u001B[0m: ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')"
     ]
    }
   ],
   "source": [
    "import pyodbc, pprint\n",
    "print(\"Drivers:\", pyodbc.drivers())\n",
    "# Try connecting DSN-less\n",
    "conn = pyodbc.connect(\n",
    "    \"Driver={ODBC Driver 18 for SQL Server};Server=localhost;Trusted_Connection=yes;\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T13:46:16.327080400Z",
     "start_time": "2025-04-23T13:46:16.131953900Z"
    }
   },
   "id": "dfcc3cf016064d97"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server',\n",
      " 'ODBC Driver 17 for SQL Server',\n",
      " 'Microsoft Access Driver (*.mdb, *.accdb)',\n",
      " 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)',\n",
      " 'Microsoft Access Text Driver (*.txt, *.csv)',\n",
      " 'Microsoft Access dBASE Driver (*.dbf, *.ndx, *.mdx)',\n",
      " 'ODBC Driver 18 for SQL Server']\n"
     ]
    }
   ],
   "source": [
    "import pyodbc, pprint\n",
    "pprint.pprint(pyodbc.drivers())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-23T14:08:24.707296700Z",
     "start_time": "2025-04-23T14:08:24.691290800Z"
    }
   },
   "id": "773febcec2ad0653"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unsloth', 'zephyr', 'chatml', 'mistral', 'llama', 'vicuna', 'vicuna_old', 'vicuna old', 'alpaca', 'gemma', 'gemma_chatml', 'gemma2', 'gemma2_chatml', 'llama-3', 'llama3', 'phi-3', 'phi-35', 'phi-3.5', 'llama-3.1', 'llama-31', 'llama-3.2', 'llama-3.3', 'llama-32', 'llama-33', 'qwen-2.5', 'qwen-25', 'qwen25', 'qwen2.5', 'phi-4', 'gemma-3', 'gemma3']\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import CHAT_TEMPLATES\n",
    "print(list(CHAT_TEMPLATES.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-30T06:25:14.103069600Z",
     "start_time": "2025-04-30T06:25:14.092429Z"
    }
   },
   "id": "946e2b5a143f9664"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… post_processing: Valid JSON detected. \n",
      " [{'Brand': 'Patek', 'Model': '7150', 'ReferenceNumber': '7150/250R', 'YearOfManufacture': '02/2025', 'Condition': 'New', 'FullSet': True, 'Price': 52000, 'Currency': 'USDT'}, {'Brand': 'RM011', 'Model': 'WG Felipe Massa', 'YearOfManufacture': '2013', 'Condition': 'like new', 'Price': 150000, 'Currency': 'USDT'}, {'Brand': 'Vacheron Constantin', 'Model': 'Tourbillon', 'ReferenceNumber': '6000V/110R-B934', 'YearOfManufacture': '2022', 'Condition': 'Brand new', 'Price': 175000, 'Currency': 'USDT'}, {'Brand': 'RM39', 'Model': '01aviation', 'YearOfManufacture': '2015', 'Condition': 'like new', 'Price': 92000, 'Currency': 'USDT'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# from openai import OpenAI\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "# python3 -m vllm.entrypoints.openai.api_server --model Qwen/Qwen3-8B-FP8 --max-model-len 10000\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "with open(\"Transformer/system_prompt.txt\", encoding=\"utf-8\") as f:\n",
    "   system_prompt = f.read()\n",
    "   \n",
    "   \n",
    "prompt1 = \"\"\"\n",
    "ðŸ“¢Good price in the market\n",
    "Patek 7150/250R\n",
    "New - 02/2025 - Fullset\n",
    "52000 USDT\n",
    "\n",
    "RM011 WG Felipe Massa \n",
    "2013>> like new \n",
    "150.000 USDT\n",
    "\n",
    "Vacheron Constantin \n",
    "Tourbillon 2022\n",
    "Brand new \n",
    "6000V/110R-B934\n",
    "175.000 USDT\n",
    "\n",
    "RM39 01aviation\n",
    "2015> like newÂ \n",
    "92000Â USDT\n",
    "\"\"\"\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-8B-FP8\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt1},\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    max_tokens=8192,\n",
    "    presence_penalty=1.5,\n",
    "    extra_body={\"chat_template_kwargs\": {\"enable_thinking\": False}},\n",
    ")\n",
    "parsed_output = json.loads(chat_response.choices[0].message.content)\n",
    "print(\"âœ… post_processing: Valid JSON detected. \\n\", parsed_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-30T06:25:48.272817100Z",
     "start_time": "2025-04-30T06:25:37.037076200Z"
    }
   },
   "id": "cdf1c7ac2575af80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.2: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4080. Num GPUs = 1. Max memory: 15.992 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3405679f93242eabc23acd16e24c493"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "            \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n",
    "            max_seq_length=4048,\n",
    "            dtype=None,\n",
    "        )\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "#example\n",
    "prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"content:\", content)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-04-30T07:17:56.870763700Z"
    }
   },
   "id": "6d4e268c3caad0c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
